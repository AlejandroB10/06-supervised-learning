{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c140ceb",
   "metadata": {},
   "source": [
    "# Lab 6: Supervised learning (graded)\n",
    "\n",
    "Sensor dataset (dumbbell biceps curl, classes A–E). Goal: clean data, reduce dimensionality keeping 99% variance, and compare single classifiers and ensembles targeting F1>90%.\n",
    "\n",
    "_Note: requires `pandas`, `scikit-learn`, `matplotlib` installed._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d315c",
   "metadata": {},
   "source": [
    "## Plan\n",
    "- Load and clean `ds_01.csv` (drop identifiers/timestamps, replace NA markers, coerce to numeric).\n",
    "- Drop columns with many NAs (high threshold) plus fixed lists (100% NA, zero variance); keep a stable feature list.\n",
    "- Common pipeline: imputation (median) + standard scaling + PCA (99% variance).\n",
    "- Single models (4 from previous labs): SVC RBF, Logistic Regression, Decision Tree, Perceptron.\n",
    "- Ensembles (4): Voting (soft), Bagging (tree base), RandomForest, ExtraTrees. Compare with `f1_macro` via stratified CV.\n",
    "- Pick best single and best ensemble; show confusion matrix and accuracy with `cross_val_predict`.\n",
    "- Fit best ensemble on full data and predict `common.csv`; if ground truth is available, report metrics; otherwise, show predictions only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d65b9d",
   "metadata": {},
   "source": [
    "## Dataset summary\n",
    "- Rows: 9,811; columns: 160; classes A–E with distribution A 2790, B 1899, C 1711, D 1608, E 1803.\n",
    "- Columns with 100% NA: `kurtosis_yaw_belt`, `skewness_yaw_belt`, `kurtosis_yaw_dumbbell`, `skewness_yaw_dumbbell`, `kurtosis_yaw_forearm`, `skewness_yaw_forearm`; ~98.6% NA in several forearm/arm cols (e.g., `kurtosis_picth_forearm`, `skewness_pitch_forearm`).\n",
    "- Non-numeric columns: `user_name`, `cvtd_timestamp`, `new_window`; the rest mostly numeric after coercion.\n",
    "- Index column `Unnamed: 0` has no predictive value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de40ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reproducibility\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4faa888",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('06-handout/ds_01.csv')\n",
    "common_path = Path('06-handout/common.csv')\n",
    "\n",
    "# columnas de identificación/tiempo que no aportan a la predicción\n",
    "meta_cols = [\"user_name\", \"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"new_window\", \"num_window\", \"Unnamed: 0\", \"\"]\n",
    "\n",
    "# columnas a eliminar siempre (sin depender del cálculo en runtime)\n",
    "na_100_cols = [\n",
    "    \"kurtosis_yaw_belt\", \"skewness_yaw_belt\", \"kurtosis_yaw_dumbbell\", \"skewness_yaw_dumbbell\",\n",
    "    \"kurtosis_yaw_forearm\", \"skewness_yaw_forearm\",\n",
    "]\n",
    "zero_var_cols = [\"amplitude_yaw_belt\", \"amplitude_yaw_dumbbell\", \"amplitude_yaw_forearm\"]\n",
    "\n",
    "missing_tokens = {\"\", 'nan', 'NA', '#DIV/0!', 'NaN', 'N/A'}\n",
    "NA_THRESHOLD = 0.95  # umbral alto de NA para descartar columnas\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df.replace(missing_tokens, np.nan, inplace=True)\n",
    "    if '' in df.columns:\n",
    "        df = df.drop(columns=[''])\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    return df\n",
    "\n",
    "def split_features_labels(df: pd.DataFrame):\n",
    "    y = df['class']\n",
    "    X = df.drop(columns=['class'])\n",
    "    drop_cols = [c for c in meta_cols if c in X.columns]\n",
    "    X = X.drop(columns=drop_cols)\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    # drop explícito de columnas 100% NA y varianza cero conocidas\n",
    "    X = X.drop(columns=[c for c in na_100_cols if c in X.columns], errors='ignore')\n",
    "    X = X.drop(columns=[c for c in zero_var_cols if c in X.columns], errors='ignore')\n",
    "    return X, y\n",
    "\n",
    "# carga inicial\n",
    "raw_df = clean_dataframe(pd.read_csv(data_path))\n",
    "X_raw, y = split_features_labels(raw_df)\n",
    "# trabajar siempre con copias para no tocar los dataframes originales\n",
    "X_work = X_raw.copy(deep=True)\n",
    "y_work = y.copy(deep=True)\n",
    "\n",
    "# resumen rápido\n",
    "print(f\"Filas={len(raw_df)}, Columnas={raw_df.shape[1]}\")\n",
    "print(f\"Clases: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# eliminación de columnas con muchos NAs (> NA_THRESHOLD)\n",
    "na_ratio = X_work.isna().mean()\n",
    "high_na_cols = na_ratio[na_ratio > NA_THRESHOLD].index.tolist()\n",
    "if high_na_cols:\n",
    "    print(f\"Drop por NA (>{NA_THRESHOLD*100:.0f}%): {len(high_na_cols)} columnas\")\n",
    "    X_work = X_work.drop(columns=high_na_cols)\n",
    "else:\n",
    "    print(\"No se detectaron columnas con NA por encima del umbral\")\n",
    "\n",
    "print('Top 10 columnas con NA:')\n",
    "print(na_ratio.sort_values(ascending=False).head(10))\n",
    "\n",
    "feature_columns = X_work.columns\n",
    "print(f\"X shape tras limpieza: {X_work.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00795082",
   "metadata": {},
   "source": [
    "### Outlier detection (optional)\n",
    "The handout suggests filtering outliers. A light IsolationForest filter is provided and disabled by default to avoid data leakage; enable only if needed and document the removal rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "APPLY_OUTLIER_FILTER = False  # pon a True si quieres filtrar antes del CV\n",
    "OUTLIER_CONTAM = 0.02         # 2% de contaminación esperada\n",
    "\n",
    "if APPLY_OUTLIER_FILTER:\n",
    "    iso = IsolationForest(contamination=OUTLIER_CONTAM, random_state=RANDOM_STATE)\n",
    "    mask = iso.fit_predict(X_work)\n",
    "    keep = mask == 1\n",
    "    print(f\"Filtrando outliers: {keep.sum()} de {len(mask)} muestras conservadas\")\n",
    "    X_work = X_work.loc[keep].reset_index(drop=True)\n",
    "    y_work = y_work.loc[keep].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b0934",
   "metadata": {},
   "source": [
    "### Common pipeline: imputation + scaling + PCA (99% variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocess():\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=0.99, random_state=RANDOM_STATE)),\n",
    "    ])\n",
    "\n",
    "preprocess = build_preprocess()\n",
    "\n",
    "# ajustar una vez para conocer nr de componentes\n",
    "pca_probe = preprocess.fit(X_work)\n",
    "pca_n = pca_probe.named_steps['pca'].n_components_\n",
    "print(f\"Componentes retenidos para 99% varianza: {pca_n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b25bd",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "The handout requires describing models/hyperparameters. These grids explore reasonable values and are evaluated with macro F1 in stratified CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "single_param_grids = {\n",
    "    'svc_rbf': {\n",
    "        'clf__C': [1, 10, 50],\n",
    "        'clf__gamma': ['scale', 0.01, 0.001],\n",
    "    },\n",
    "    'logreg': {\n",
    "        'clf__C': [0.5, 1, 5, 10],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__multi_class': ['auto'],\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    'perceptron': {\n",
    "        'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "        'clf__penalty': [None, 'l2'],\n",
    "    },\n",
    "}\n",
    "\n",
    "ensemble_param_grids = {\n",
    "    'voting_soft': {\n",
    "        # Ajustar estimadores internos si se desea\n",
    "    },\n",
    "    'bagging_tree': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__estimator__max_depth': [None, 10, 20],\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'clf__n_estimators': [150, 300],\n",
    "        'clf__max_depth': [None, 15, 25],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'clf__n_estimators': [150, 300],\n",
    "        'clf__max_depth': [None, 15, 25],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def run_grid_search(model_name, estimator, param_grid):\n",
    "    pipe = Pipeline([\n",
    "        ('prep', build_preprocess()),\n",
    "        ('clf', estimator),\n",
    "    ])\n",
    "    gs = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "    gs.fit(X_work, y_work)\n",
    "    return gs\n",
    "\n",
    "# Ejemplo de uso (ejecutar manualmente cuando quieras explorar):\n",
    "# gs_svc = run_grid_search('svc_rbf', single_models['svc_rbf'], single_param_grids['svc_rbf'])\n",
    "# print(gs_svc.best_params_, gs_svc.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c06454",
   "metadata": {},
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b728caf",
   "metadata": {},
   "source": [
    "## Required results (handout)\n",
    "- Table of single-classifier runs (model, hyperparameters tried, mean/std F1 in CV).\n",
    "- Table of ensemble runs with their F1.\n",
    "- For the best single and the best ensemble: use `cross_val_predict` to get confusion matrix and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Modelos individuales basados en labs previos\n",
    "single_models = {\n",
    "    'svc_rbf': SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced', random_state=RANDOM_STATE),  # lab1\n",
    "    'logreg': LogisticRegression(max_iter=400, multi_class='auto', n_jobs=-1, class_weight='balanced', random_state=RANDOM_STATE),  # lab4\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE),  # lab5\n",
    "    'perceptron': Perceptron(max_iter=1000, random_state=RANDOM_STATE),  # lab3\n",
    "}\n",
    "\n",
    "# Ensembles (4 opciones)\n",
    "ensemble_models = {\n",
    "    'voting_soft': VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svc', SVC(kernel='rbf', C=10, gamma='scale', probability=True, class_weight='balanced', random_state=RANDOM_STATE)),\n",
    "            ('dt', DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
    "            ('log', LogisticRegression(max_iter=400, multi_class='auto', n_jobs=-1, class_weight='balanced', random_state=RANDOM_STATE)),\n",
    "        ],\n",
    "        voting='soft'\n",
    "    ),\n",
    "    'bagging_tree': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'random_forest': RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'extra_trees': ExtraTreesClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f0209",
   "metadata": {},
   "source": [
    "## Evaluation (`f1_macro`, stratified CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91178f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(model_dict, X, y, cv):\n",
    "    rows = []\n",
    "    for name, estimator in model_dict.items():\n",
    "        pipe = Pipeline([\n",
    "            ('prep', build_preprocess()),\n",
    "            ('clf', estimator),\n",
    "        ])\n",
    "        scores = cross_val_score(pipe, X, y, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "        rows.append({'model': name, 'f1_mean': scores.mean(), 'f1_std': scores.std()})\n",
    "        print(f\"{name}: f1_mean={scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "    return pd.DataFrame(rows).sort_values('f1_mean', ascending=False)\n",
    "\n",
    "single_results = evaluate_models(single_models, X_work, y_work, cv)\n",
    "ensemble_results = evaluate_models(ensemble_models, X_work, y_work, cv)\n",
    "\n",
    "single_results, ensemble_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4666b2",
   "metadata": {},
   "source": [
    "## Best single model: confusion matrix and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d598b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_single_name = single_results.iloc[0]['model'] if not single_results.empty else None\n",
    "if best_single_name:\n",
    "    best_single = Pipeline([\n",
    "        ('prep', build_preprocess()),\n",
    "        ('clf', single_models[best_single_name]),\n",
    "    ])\n",
    "    y_pred_cv = cross_val_predict(best_single, X_work, y_work, cv=cv, n_jobs=-1)\n",
    "    print(classification_report(y, y_pred_cv))\n",
    "    print(f\"Accuracy = {accuracy_score(y, y_pred_cv):.4f}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred_cv)\n",
    "    plt.title(f\"Confusion matrix - {best_single_name}\")\n",
    "else:\n",
    "    print(\"No hay resultados de modelos individuales.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260017a",
   "metadata": {},
   "source": [
    "## Best ensemble: confusion matrix and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ensemble_name = ensemble_results.iloc[0]['model'] if not ensemble_results.empty else None\n",
    "if best_ensemble_name:\n",
    "    best_ensemble = Pipeline([\n",
    "        ('prep', build_preprocess()),\n",
    "        ('clf', ensemble_models[best_ensemble_name]),\n",
    "    ])\n",
    "    y_pred_cv = cross_val_predict(best_ensemble, X_work, y_work, cv=cv, n_jobs=-1)\n",
    "    print(classification_report(y, y_pred_cv))\n",
    "    print(f\"Accuracy = {accuracy_score(y, y_pred_cv):.4f}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred_cv)\n",
    "    plt.title(f\"Confusion matrix - {best_ensemble_name}\")\n",
    "else:\n",
    "    print(\"No hay resultados de ensembles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da125c57",
   "metadata": {},
   "source": [
    "**Note on `common.csv`:** the `class` column looks like an ID (1..20) rather than labels A–E. The code predicts A–E with the best model; if true labels exist, map them and compute confusion/accuracy, otherwise just show predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284be97",
   "metadata": {},
   "source": [
    "## Prediction on `common.csv`\n",
    "Reuse `feature_columns` and the best ensemble. If labels in `common.csv` are not in {A,B,C,D,E}, show predictions without accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df = clean_dataframe(pd.read_csv(common_path))\n",
    "X_common, y_common = split_features_labels(common_df)\n",
    "# asegurar mismas columnas/orden\n",
    "X_common = X_common.reindex(columns=feature_columns)\n",
    "\n",
    "if best_ensemble_name is None:\n",
    "    print(\"No hay ensemble entrenado.\")\n",
    "else:\n",
    "    best_ensemble = Pipeline([\n",
    "        ('prep', build_preprocess()),\n",
    "        ('clf', ensemble_models[best_ensemble_name]),\n",
    "    ])\n",
    "    best_ensemble.fit(X_work, y_work)\n",
    "    common_pred = best_ensemble.predict(X_common)\n",
    "    common_df_out = pd.DataFrame({'true': y_common, 'pred': common_pred})\n",
    "    if set(y_common.unique()).issubset(set(y.unique())):\n",
    "        print(classification_report(y_common, common_pred))\n",
    "        print(f\"Accuracy common = {accuracy_score(y_common, common_pred):.4f}\")\n",
    "        ConfusionMatrixDisplay.from_predictions(y_common, common_pred)\n",
    "        plt.title(\"Confusion matrix - common.csv\")\n",
    "    else:\n",
    "        print(\"Las etiquetas en common.csv no coinciden con las de entrenamiento; se muestran solo predicciones:\")\n",
    "        print(common_df_out)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
